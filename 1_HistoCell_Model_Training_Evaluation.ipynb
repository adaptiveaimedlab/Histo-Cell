{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\39351\\anaconda3\\envs\\TFgpuKeras\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from   tensorflow.keras.models import Model\n",
    "from   tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from   tensorflow.keras.applications import EfficientNetB3, EfficientNetB0, EfficientNetB1\n",
    "from   tensorflow.keras.layers import Conv2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import EfficientNetB3, ResNet50, MobileNetV3Large\n",
    "from tensorflow.keras.layers import Conv2D, Multiply, Reshape, Input, GlobalMaxPooling2D, Add, BatchNormalization, GlobalAveragePooling2D, Dense\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "import math\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters and Hyperparameters settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "batch_size = 256\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "IMG_SIZE = img_height\n",
    "epochs = 12\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_block(input_tensor, reduction=16):\n",
    "    channel_axis = -1\n",
    "    filters = input_tensor.shape[channel_axis]\n",
    "\n",
    "    # Channel-wise attention (SE Block)\n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Reshape((1, 1, filters))(se)\n",
    "    se = Dense(filters // reduction, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Multiply()([input_tensor, se])\n",
    "\n",
    "    # Spatial attention\n",
    "    spatial = Conv2D(filters // reduction, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', use_bias=False)(input_tensor)\n",
    "    spatial = BatchNormalization()(spatial)\n",
    "    spatial = Conv2D(1, (1, 1), activation='sigmoid', padding='same', kernel_initializer='he_normal', use_bias=False)(spatial)\n",
    "\n",
    "    # Apply spatial attention\n",
    "    spatial = Multiply()([input_tensor, spatial])\n",
    "\n",
    "    # Combine channel-wise and spatial attentions\n",
    "    x = Add()([input_tensor, se, spatial])\n",
    "    return x\n",
    "\n",
    "# Convolutional Block Attention Module (CBAM)\n",
    "def cbam_block(input_tensor, reduction=16):\n",
    "    channel = input_tensor.shape[-1]\n",
    "    \n",
    "    # Channel attention\n",
    "    avg_pool = GlobalAveragePooling2D()(input_tensor)\n",
    "    max_pool = GlobalMaxPooling2D()(input_tensor)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "    dense1 = Dense(channel // reduction, activation='relu', kernel_initializer='he_normal', use_bias=False)\n",
    "    dense2 = Dense(channel, kernel_initializer='he_normal', use_bias=False)\n",
    "    avg_out = dense2(dense1(avg_pool))\n",
    "    max_out = dense2(dense1(max_pool))\n",
    "    channel_attention = layers.Add()([avg_out, max_out])\n",
    "    channel_attention = layers.Activation('sigmoid')(channel_attention)\n",
    "    x = Multiply()([input_tensor, channel_attention])\n",
    "    \n",
    "    # Spatial attention\n",
    "    avg_pool = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "    max_pool = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "    spatial_attention = Conv2D(1, (7, 7),dilation_rate= 2, padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(concat)\n",
    "    x = Multiply()([x, spatial_attention])\n",
    "    \n",
    "    return x\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, num_heads, embed_dim, ff_dim, rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_heads': self.num_heads,\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'ff_dim': self.ff_dim,\n",
    "            'rate': self.rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def create_model(img_height=224, img_width=224, num_classes=4):\n",
    "    inputs = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "    # First EfficientNetB3 instance\n",
    "    efficient_net_b3_1 = EfficientNetB3(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n",
    "    #efficient_net_b3_1.summary()\n",
    "    x = efficient_net_b3_1.output\n",
    "\n",
    "    # Pyramid module with SE blocks and CBAM\n",
    "    c5 = se_block(x)\n",
    "    p4 = Conv2D(filters=64, kernel_size=(1, 1), activation='relu')(c5)\n",
    "    p4 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(p4)\n",
    "\n",
    "    # Second EfficientNetB3 instance\n",
    "    c4 = efficient_net_b3_1.get_layer('block4a_expand_activation').output\n",
    "    c4 = cbam_block(c4)\n",
    "    c4 = Conv2D(filters=64, kernel_size=(1, 1), activation='relu')(c4)\n",
    "    c4 = layers.Lambda(lambda x: tf.image.resize(x, (2, 2)))(c4)\n",
    "    p4 = layers.Concatenate()([p4, c4])\n",
    "\n",
    "    p3 = Conv2D(filters=64, kernel_size=(1, 1), dilation_rate=(2, 2), activation='relu')(p4)\n",
    "    p3 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(p3)\n",
    "\n",
    "    # Third EfficientNetB3 instance\n",
    "    c3 = efficient_net_b3_1.get_layer('block3a_expand_activation').output\n",
    "    c3 = cbam_block(c3)\n",
    "    c3 = Conv2D(filters=64, kernel_size=(1, 1), activation='relu')(c3)\n",
    "    c3 = layers.Lambda(lambda x: tf.image.resize(x, (4, 4)))(c3)\n",
    "    p3 = layers.Concatenate()([p3, c3])\n",
    "\n",
    "    x = TransformerBlock(num_heads=4, embed_dim=128, ff_dim=96, rate=0.3)(p3)\n",
    "    x = layers.Reshape((int(x.shape[1]), int(x.shape[2]), int(x.shape[3])))(x)\n",
    "    x_c1 = layers.Conv2D(64, (3, 3), padding='same', dilation_rate=(2, 2), activation='relu')(x)\n",
    "    x_c01 = TransformerBlock(num_heads=4, embed_dim=64, ff_dim=64, rate=0.3)(x_c1)\n",
    "    x_c001 = layers.Reshape((int(x_c01.shape[1]), int(x_c01.shape[2]), int(x_c01.shape[3])))(x_c01)\n",
    "    x_c11 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x_c001)\n",
    "    x_c11 = layers.BatchNormalization()(x_c11)\n",
    "    x_c2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x_c11)\n",
    "    combined1 = layers.Concatenate()([x_c1, x_c2])\n",
    "    x = layers.MaxPooling2D()(combined1)\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(96, activation='relu', name=\"features_vector\")(x)\n",
    "\n",
    "    if num_classes == 2:\n",
    "        x = layers.Dense(1, activation='sigmoid', name=\"pred\")(x)\n",
    "    else:\n",
    "        x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model_created = Model(inputs=inputs, outputs=x)\n",
    "    return model_created\n",
    "\n",
    "def create_base_model(model_name, img_height=32, img_width=32, num_classes=4):\n",
    "    if model_name == 'ResNet50':\n",
    "        base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
    "    elif model_name == 'MobileNetV3Large':\n",
    "        base_model = MobileNetV3Large(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
    "    elif model_name == 'EfficientNetB3':\n",
    "        base_model = EfficientNetB3(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
    "    else:\n",
    "        raise ValueError(\"Model name not recognized. Choose from 'ResNet50', 'MobileNetV3Large', or 'EfficientNetB3'.\")\n",
    "\n",
    "    # Add custom classification head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training set counts: {'01_Fat': 65445, '02_Stroma': 91662, '03_Tumor': 94544}\n",
      "Fold 1 - Validation set counts: {'01_Fat': 34776, '02_Stroma': 68405, '03_Tumor': 31539}\n",
      "Training on fold 1...\n",
      "tf.keras code in this scope will run on GPU\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_1 (Rescaling)         (None, 32, 32, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization_1 (Normalization) (None, 32, 32, 3)    7           rescaling_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 33, 33, 3)    0           normalization_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 16, 16, 40)   1080        stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 16, 16, 40)   160         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 16, 16, 40)   0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 16, 16, 40)   360         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 16, 16, 40)   160         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 16, 16, 40)   0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 40)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 40)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 10)     410         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 40)     440         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 16, 16, 40)   0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 16, 16, 24)   960         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 16, 16, 24)   96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 16, 16, 24)   216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 16, 16, 24)   96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 16, 16, 24)   0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 16, 16, 24)   0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 16, 16, 24)   576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 16, 16, 24)   96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 16, 16, 24)   0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 16, 16, 24)   0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 16, 16, 144)  3456        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 16, 16, 144)  576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 16, 16, 144)  0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 17, 17, 144)  0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 8, 8, 144)    1296        block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 8, 8, 144)    576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 8, 8, 144)    0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 8, 8, 144)    0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 8, 8, 32)     4608        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 8, 8, 32)     128         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 8, 8, 192)    6144        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 8, 8, 192)    768         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 8, 8, 192)    0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 8, 8, 192)    1728        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 8, 8, 192)    768         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 8, 8, 192)    0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 192)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 8, 8, 192)    0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 8, 8, 32)     6144        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 8, 8, 32)     128         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 8, 8, 32)     0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 8, 8, 32)     0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 8, 8, 192)    6144        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 8, 8, 192)    768         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 8, 8, 192)    0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 8, 8, 192)    1728        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 8, 8, 192)    768         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 8, 8, 192)    0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 192)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 8, 8, 192)    0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 8, 8, 32)     6144        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 8, 8, 32)     128         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 8, 8, 32)     0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 8, 8, 32)     0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 8, 8, 192)    6144        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 8, 8, 192)    768         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 8, 8, 192)    0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 11, 11, 192)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 4, 4, 192)    4800        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 4, 4, 192)    768         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 4, 4, 192)    0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 192)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 4, 4, 192)    0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 4, 4, 48)     9216        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 4, 4, 48)     192         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 4, 4, 288)    13824       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 4, 4, 288)    1152        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 4, 4, 288)    0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 4, 4, 288)    7200        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 4, 4, 288)    1152        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 4, 4, 288)    0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 288)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 4, 4, 288)    0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 4, 4, 48)     13824       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 4, 4, 48)     192         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 4, 4, 48)     0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 4, 4, 48)     0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 4, 4, 288)    13824       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 4, 4, 288)    1152        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 4, 4, 288)    0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 4, 4, 288)    7200        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 4, 4, 288)    1152        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 4, 4, 288)    0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 288)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 4, 4, 288)    0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 4, 4, 48)     13824       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 4, 4, 48)     192         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 4, 4, 48)     0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 4, 4, 48)     0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 4, 4, 288)    13824       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 4, 4, 288)    1152        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 4, 4, 288)    0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 5, 5, 288)    0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 2, 2, 288)    2592        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 2, 2, 288)    1152        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 2, 2, 288)    0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 288)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 2, 2, 288)    0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 2, 2, 96)     27648       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 2, 2, 96)     384         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 2, 2, 576)    55296       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 2, 2, 576)    2304        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 2, 2, 576)    0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 2, 2, 576)    5184        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 2, 2, 576)    2304        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 2, 2, 576)    0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 576)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 2, 2, 576)    0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 2, 2, 96)     55296       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 2, 2, 96)     384         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 2, 2, 96)     0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 2, 2, 96)     0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 2, 2, 576)    55296       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 2, 2, 576)    2304        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 2, 2, 576)    0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 2, 2, 576)    5184        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 2, 2, 576)    2304        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 2, 2, 576)    0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 576)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 2, 2, 576)    0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 2, 2, 96)     55296       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 2, 2, 96)     384         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 2, 2, 96)     0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 2, 2, 96)     0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 2, 2, 576)    55296       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 2, 2, 576)    2304        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 2, 2, 576)    0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 2, 2, 576)    5184        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 2, 2, 576)    2304        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 2, 2, 576)    0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 576)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 2, 2, 576)    0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 2, 2, 96)     55296       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 2, 2, 96)     384         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 2, 2, 96)     0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 2, 2, 96)     0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 2, 2, 576)    55296       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 2, 2, 576)    2304        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 2, 2, 576)    0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 2, 2, 576)    5184        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 2, 2, 576)    2304        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 2, 2, 576)    0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 576)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 2, 2, 576)    0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 2, 2, 96)     55296       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 2, 2, 96)     384         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (Dropout)          (None, 2, 2, 96)     0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 2, 2, 96)     0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 2, 2, 576)    55296       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 2, 2, 576)    2304        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 2, 2, 576)    0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 2, 2, 576)    14400       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 2, 2, 576)    2304        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 2, 2, 576)    0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 576)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 576)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 2, 2, 576)    0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 2, 2, 136)    78336       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 2, 2, 136)    544         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 2, 2, 816)    110976      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 2, 2, 816)    3264        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 2, 2, 816)    0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 2, 2, 816)    20400       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 2, 2, 816)    3264        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 2, 2, 816)    0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 816)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 2, 2, 816)    0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 2, 2, 136)    110976      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 2, 2, 136)    544         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 2, 2, 136)    0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 2, 2, 136)    0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 2, 2, 816)    110976      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 2, 2, 816)    3264        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 2, 2, 816)    0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 2, 2, 816)    20400       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 2, 2, 816)    3264        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 2, 2, 816)    0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 816)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 2, 2, 816)    0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 2, 2, 136)    110976      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 2, 2, 136)    544         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 2, 2, 136)    0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 2, 2, 136)    0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 2, 2, 816)    110976      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 2, 2, 816)    3264        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 2, 2, 816)    0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 2, 2, 816)    20400       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 2, 2, 816)    3264        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 2, 2, 816)    0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 816)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 2, 2, 816)    0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 2, 2, 136)    110976      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 2, 2, 136)    544         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 2, 2, 136)    0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 2, 2, 136)    0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 2, 2, 816)    110976      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 2, 2, 816)    3264        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 2, 2, 816)    0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 2, 2, 816)    20400       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 2, 2, 816)    3264        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 2, 2, 816)    0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 816)          0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 2, 2, 816)    0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 2, 2, 136)    110976      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 2, 2, 136)    544         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (Dropout)          (None, 2, 2, 136)    0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 2, 2, 136)    0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 2, 2, 816)    110976      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 2, 2, 816)    3264        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 2, 2, 816)    0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 5, 5, 816)    0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 1, 1, 816)    20400       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 1, 1, 816)    3264        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 1, 1, 816)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 816)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 816)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 1, 1, 816)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 1, 1, 232)    189312      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 1, 1, 232)    928         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 1, 1, 1392)   322944      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 1, 1, 1392)   5568        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 1, 1, 1392)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 1, 1, 1392)   34800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 1, 1, 1392)   5568        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 1, 1, 1392)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1392)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 1, 1, 1392)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 1, 1, 232)    322944      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 1, 1, 232)    928         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 1, 1, 232)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 1, 1, 232)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 1, 1, 1392)   322944      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 1, 1, 1392)   5568        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 1, 1, 1392)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 1, 1, 1392)   34800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 1, 1, 1392)   5568        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 1, 1, 1392)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1392)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 1, 1, 1392)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 1, 1, 232)    322944      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 1, 1, 232)    928         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 1, 1, 232)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 1, 1, 232)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 1, 1, 1392)   322944      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 1, 1, 1392)   5568        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 1, 1, 1392)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 1, 1, 1392)   34800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 1, 1, 1392)   5568        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 1, 1, 1392)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1392)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 1, 1, 1392)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 1, 1, 232)    322944      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 1, 1, 232)    928         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 1, 1, 232)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 1, 1, 232)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 1, 1, 1392)   322944      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 1, 1, 1392)   5568        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 1, 1, 1392)   0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 1, 1, 1392)   34800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 1, 1, 1392)   5568        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 1, 1, 1392)   0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1392)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 1, 1, 1392)   0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 1, 1, 232)    322944      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 1, 1, 232)    928         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 1, 1, 232)    0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 1, 1, 232)    0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 1, 1, 1392)   322944      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 1, 1, 1392)   5568        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 1, 1, 1392)   0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 1, 1, 1392)   34800       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 1, 1, 1392)   5568        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 1, 1, 1392)   0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1392)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 1, 1, 1392)   0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 1, 1, 232)    322944      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 1, 1, 232)    928         block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (Dropout)          (None, 1, 1, 232)    0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 1, 1, 232)    0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 1, 1, 1392)   322944      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 1, 1, 1392)   5568        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 1, 1, 1392)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 1, 1, 1392)   12528       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 1, 1, 1392)   5568        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 1, 1, 1392)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1392)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 1, 1, 1392)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 1, 1, 384)    534528      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 1, 1, 384)    1536        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 1, 1, 2304)   884736      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 1, 1, 2304)   9216        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 1, 1, 2304)   0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 1, 1, 2304)   20736       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 1, 1, 2304)   9216        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 1, 1, 2304)   0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2304)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 1, 1, 2304)   0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 1, 1, 384)    884736      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 1, 1, 384)    1536        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 1, 1, 384)    0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 288)          0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 288)          0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 1, 1, 384)    0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1, 288)    0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1, 288)    0           global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 1, 1, 1536)   589824      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1, 1, 18)     5184        reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 1, 1, 1536)   6144        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1, 1, 288)    5184        dense_14[0][0]                   \n",
      "                                                                 dense_14[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 192)          0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 192)          0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 1, 1, 1536)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1, 1, 288)    0           dense_15[0][0]                   \n",
      "                                                                 dense_15[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1, 192)    0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1, 192)    0           global_max_pooling2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 1536)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 1, 288)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1, 1, 12)     2304        reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 1536)   0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 1, 1, 96)     147456      top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 4, 4, 288)    0           block4a_expand_activation[0][0]  \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1, 1, 192)    2304        dense_16[0][0]                   \n",
      "                                                                 dense_16[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1, 1, 96)     147456      reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 1, 96)     384         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_2 (TFOpLamb (None, 4, 4, 1)      0           multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_max_2 (TFOpLambd (None, 4, 4, 1)      0           multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1, 1, 192)    0           dense_17[0][0]                   \n",
      "                                                                 dense_17[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1, 1, 1536)   147456      dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 1, 1)      96          batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4, 4, 2)      0           tf.math.reduce_mean_2[0][0]      \n",
      "                                                                 tf.math.reduce_max_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, 1, 192)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 1, 1, 1536)   0           top_activation[0][0]             \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 1, 1, 1536)   0           top_activation[0][0]             \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 1)      98          concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 8, 8, 192)    0           block3a_expand_activation[0][0]  \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1, 1, 1536)   0           top_activation[0][0]             \n",
      "                                                                 multiply_6[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 4, 4, 288)    0           multiply_8[0][0]                 \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_3 (TFOpLamb (None, 8, 8, 1)      0           multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_max_3 (TFOpLambd (None, 8, 8, 1)      0           multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1, 1, 64)     98368       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 64)     18496       multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 8, 2)      0           tf.math.reduce_mean_3[0][0]      \n",
      "                                                                 tf.math.reduce_max_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 2, 2, 64)     0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2, 2, 64)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 1)      98          concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 2, 2, 128)    0           up_sampling2d_2[0][0]            \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 8, 8, 192)    0           multiply_10[0][0]                \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 2, 2, 64)     8256        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 64)     12352       multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 4, 4, 64)     0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 4, 4, 64)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 4, 4, 128)    0           up_sampling2d_3[0][0]            \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_2 (Transforme (None, 4, 4, 128)    289120      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 4, 4, 128)    0           transformer_block_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 64)     73792       reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_3 (Transforme (None, 4, 4, 64)     74944       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 4, 4, 64)     0           transformer_block_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 32)     18464       reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4, 4, 32)     128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 4, 4, 32)     9248        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 4, 4, 96)     0           conv2d_19[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 2, 2, 96)     0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 384)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 256)          98560       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "features_vector (Dense)         (None, 96)           24672       dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 3)            291         features_vector[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 11,968,246\n",
      "Trainable params: 11,880,687\n",
      "Non-trainable params: 87,559\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AdamW optimizer\n",
    "optimizer = AdamW(learning_rate=0.001, weight_decay=1e-4)\n",
    "\n",
    "def advanced_schedule(epoch, initial_lr=1e-4, warmup_epochs=5, total_epochs=10, min_lr=1e-6):\n",
    "    \"\"\"\n",
    "    Learning rate schedule with warmup and cosine annealing.\n",
    "\n",
    "    Parameters:\n",
    "    - epoch: The current epoch.\n",
    "    - initial_lr: Learning rate at the start of the warmup period.\n",
    "    - warmup_epochs: Number of epochs to linearly increase the learning rate.\n",
    "    - total_epochs: Total number of epochs for the cosine annealing schedule.\n",
    "    - min_lr: Minimum learning rate to avoid reducing the learning rate too much.\n",
    "\n",
    "    Returns:\n",
    "    - lr: The learning rate for the current epoch.\n",
    "    \"\"\"\n",
    "    if epoch < warmup_epochs:\n",
    "        # Linear warmup\n",
    "        lr = initial_lr * (epoch / warmup_epochs)\n",
    "    else:\n",
    "        # Cosine annealing after warmup\n",
    "        effective_epoch = epoch - warmup_epochs\n",
    "        progress = effective_epoch / (total_epochs - warmup_epochs)\n",
    "        lr = initial_lr * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "    \n",
    "    # Ensure learning rate does not drop below minimum value\n",
    "    lr = max(lr, min_lr)\n",
    "    \n",
    "    return lr\n",
    "advanced_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: advanced_schedule(epoch))\n",
    "\n",
    "# Function to recursively gather image paths and labels from all categories, grouped by patient\n",
    "def gather_image_paths_and_labels(data_dir):\n",
    "    categories = ['01_Fat', '02_Stroma', '03_Tumor']\n",
    "    patient_image_paths = {}\n",
    "    label_map = {category: idx for idx, category in enumerate(categories)}\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']  # Add other valid image extensions if necessary\n",
    "    \n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        for patient_folder in sorted(os.listdir(category_path)):\n",
    "            patient_folder_path = os.path.join(category_path, patient_folder)\n",
    "            if os.path.isdir(patient_folder_path):\n",
    "                patient_id = os.path.join(category, patient_folder)\n",
    "                if patient_id not in patient_image_paths:\n",
    "                    patient_image_paths[patient_id] = {'image_paths': [], 'label': label_map[category]}\n",
    "                # Recursively search for image files\n",
    "                for root, _, files in os.walk(patient_folder_path):\n",
    "                    for file in files:\n",
    "                        if any(file.lower().endswith(ext) for ext in valid_image_extensions):\n",
    "                            patient_image_paths[patient_id]['image_paths'].append(os.path.join(root, file))\n",
    "    \n",
    "    return patient_image_paths\n",
    "\n",
    "# Modify the `create_dataset` function to include sample weights\n",
    "def create_dataset(image_paths, labels, sample_weights=None, image_size=(224, 224), batch_size=32, one_hot=False, num_classes=3):\n",
    "    ds = []\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    image_ds = path_ds.map(lambda x: tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(x), channels=3), image_size))\n",
    "\n",
    "    if one_hot:\n",
    "        labels = tf.keras.utils.to_categorical(labels, num_classes=num_classes)\n",
    "    \n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(labels, tf.float32))\n",
    "    \n",
    "    if sample_weights is not None:\n",
    "        sample_weight_ds = tf.data.Dataset.from_tensor_slices(tf.cast(sample_weights, tf.float32))\n",
    "        ds = tf.data.Dataset.zip((image_ds, label_ds, sample_weight_ds))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=len(image_paths))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "# Function to count images per category\n",
    "def count_images_per_category(image_paths, labels, categories):\n",
    "    category_counts = {category: 0 for category in categories}\n",
    "    for label in labels:\n",
    "        category = categories[label]\n",
    "        category_counts[category] += 1\n",
    "    return category_counts\n",
    "\n",
    "\n",
    "def evaluate_metrics(val_true, val_pred):\n",
    "    cm = confusion_matrix(val_true, val_pred)\n",
    "    #print(\"Confusion Matrix:\\n\", cm)\n",
    "    \n",
    "    sensitivity = sensitivity_multiclass(cm)\n",
    "    specificity = specificity_multiclass(cm)\n",
    "    f1 = f1_score_multiclass(cm)\n",
    "    accuracy = accuracy_multiclass(cm)\n",
    "    iou = iou_multiclass(cm)\n",
    "    \n",
    "    '''print(f\"Sensitivity: {sensitivity}\")\n",
    "    print(f\"Specificity: {specificity}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"IoU: {iou}\")'''\n",
    "\n",
    "    # Detailed classification report\n",
    "    #print(\"\\nClassification Report:\\n\", classification_report(val_true, val_pred))\n",
    "    \n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_data):\n",
    "        super().__init__()\n",
    "        self.val_data = val_data\n",
    "        self.sensitivities = []\n",
    "        self.specificities = []\n",
    "        self.f1_scores = []\n",
    "        self.accuracies = []\n",
    "        self.ious = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_true = []\n",
    "        val_pred = []\n",
    "\n",
    "        for images, labels in self.val_data:\n",
    "            preds = self.model.predict(images)\n",
    "            val_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "            val_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "        val_true = np.array(val_true)\n",
    "        val_pred = np.array(val_pred)\n",
    "\n",
    "        cm = confusion_matrix(val_true, val_pred)\n",
    "        sensitivity = sensitivity_multiclass(cm)\n",
    "        specificity = specificity_multiclass(cm)\n",
    "        f1 = f1_score_multiclass(cm)\n",
    "        accuracy = accuracy_multiclass(cm)\n",
    "        iou = iou_multiclass(cm)\n",
    "\n",
    "\n",
    "        evaluate_metrics(val_true, val_pred)\n",
    "\n",
    "        self.sensitivities.append(sensitivity)\n",
    "        self.specificities.append(specificity)\n",
    "        self.f1_scores.append(f1)\n",
    "        self.accuracies.append(accuracy)\n",
    "        self.ious.append(iou)\n",
    "\n",
    "        logs['val_sensitivity'] = sensitivity\n",
    "        logs['val_specificity'] = specificity\n",
    "        logs['val_f1'] = f1\n",
    "        logs['val_accuracy'] = accuracy\n",
    "        logs['val_iou'] = iou\n",
    "\n",
    "\n",
    "        '''# Update logs if necessary\n",
    "        logs['val_sensitivity'] = sensitivity_multiclass(confusion_matrix(val_true, val_pred))\n",
    "        logs['val_specificity'] = specificity_multiclass(confusion_matrix(val_true, val_pred))\n",
    "        logs['val_f1'] = f1_score_multiclass(confusion_matrix(val_true, val_pred))\n",
    "        logs['val_accuracy'] = accuracy_multiclass(confusion_matrix(val_true, val_pred))\n",
    "        logs['val_iou'] = iou_multiclass(confusion_matrix(val_true, val_pred))'''\n",
    "\n",
    "        print(f\" — val_sensitivity: {sensitivity} — val_specificity: {specificity} — val_f1: {f1} — val_accuracy: {accuracy} — val_iou: {iou}\")\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return {\n",
    "            'average_sensitivity': np.mean(self.sensitivities),\n",
    "            'average_specificity': np.mean(self.specificities),\n",
    "            'average_f1': np.mean(self.f1_scores),\n",
    "            'average_accuracy': np.mean(self.accuracies),\n",
    "            'average_iou': np.mean(self.ious)\n",
    "        }\n",
    "\n",
    "def accuracy_multiclass(confusion_matrix):\n",
    "    true_positives = np.diag(confusion_matrix)\n",
    "    total_samples = np.sum(confusion_matrix)\n",
    "    accuracy = np.sum(true_positives) / total_samples\n",
    "    return accuracy\n",
    "\n",
    "def sensitivity_multiclass(confusion_matrix):\n",
    "    sensitivities = []\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        true_positives = confusion_matrix[i, i]\n",
    "        false_negatives = np.sum(confusion_matrix[i, :]) - true_positives\n",
    "        sensitivity = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        sensitivities.append(sensitivity)\n",
    "    return np.mean(sensitivities)\n",
    "\n",
    "def specificity_multiclass(confusion_matrix):\n",
    "    specificities = []\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        true_negatives = np.sum(np.delete(np.delete(confusion_matrix, i, axis=0), i, axis=1))\n",
    "        false_positives = np.sum(np.delete(confusion_matrix[:, i], i))\n",
    "        specificity = true_negatives / (true_negatives + false_positives)\n",
    "        specificities.append(specificity)\n",
    "    return np.mean(specificities)\n",
    "\n",
    "def f1_score_multiclass(confusion_matrix):\n",
    "    f1_scores = []\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        true_positives = confusion_matrix[i, i]\n",
    "        false_positives = np.sum(confusion_matrix[:, i]) - true_positives\n",
    "        false_negatives = np.sum(confusion_matrix[i, :]) - true_positives\n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f1_scores.append(f1)\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "def iou_multiclass(confusion_matrix):\n",
    "    iou_list = []\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        true_positive = confusion_matrix[i, i]\n",
    "        false_positive = np.sum(confusion_matrix[:, i]) - true_positive\n",
    "        false_negative = np.sum(confusion_matrix[i, :]) - true_positive\n",
    "        iou = true_positive / (true_positive + false_positive + false_negative) if (true_positive + false_positive + false_negative) > 0 else 0\n",
    "        iou_list.append(iou)\n",
    "    return np.mean(iou_list)\n",
    "\n",
    "# Compute sample weights based on tile distribution\n",
    "def compute_sample_weights(patient_ids):\n",
    "    unique_ids, counts = np.unique(patient_ids, return_counts=True)\n",
    "    total_tiles = np.sum(counts)\n",
    "    sample_weights = np.array([total_tiles / count for count in counts])\n",
    "    \n",
    "    # Normalize the weights so they sum to 1\n",
    "    sample_weights /= np.sum(sample_weights)\n",
    "    \n",
    "    # Create a dictionary mapping patient_id to its corresponding weight\n",
    "    weight_dict = {patient_id: weight for patient_id, weight in zip(unique_ids, sample_weights)}\n",
    "    \n",
    "    return weight_dict\n",
    "\n",
    "# Define weighted focal loss\n",
    "def weighted_focal_loss(gamma=2.0):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        cross_entropy = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "        prob_true = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "        weight = tf.reduce_sum(y_true, axis=-1)\n",
    "        focal_loss = weight * tf.pow((1.0 - prob_true), gamma) * cross_entropy\n",
    "        return tf.reduce_mean(focal_loss)\n",
    "    return focal_loss\n",
    "\n",
    "\n",
    "# Plotting accuracy and loss for both training and validation\n",
    "def plot_training_history(history):\n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validate(data_dir, k=5, image_size=(224, 224), batch_size=32, epochs=10):\n",
    "    categories = ['01_Fat', '02_Stroma', '03_Tumor']\n",
    "    patient_image_paths = gather_image_paths_and_labels(data_dir)\n",
    "    patient_ids = np.array(list(patient_image_paths.keys()))\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=415)\n",
    "    \n",
    "    fold_no = 1\n",
    "    all_sensitivities = []\n",
    "    all_specificities = []\n",
    "    all_f1_scores = []\n",
    "    all_accuracies = []\n",
    "    all_ious = []\n",
    "\n",
    "    for train_index, val_index in kf.split(patient_ids):\n",
    "        train_patient_ids = patient_ids[train_index]\n",
    "        val_patient_ids = patient_ids[val_index]\n",
    "\n",
    "        train_image_paths = []\n",
    "        train_labels = []\n",
    "        for patient_id in train_patient_ids:\n",
    "            train_image_paths.extend(patient_image_paths[patient_id]['image_paths'])\n",
    "            train_labels.extend([patient_image_paths[patient_id]['label']] * len(patient_image_paths[patient_id]['image_paths']))\n",
    "\n",
    "        val_image_paths = []\n",
    "        val_labels = []\n",
    "        for patient_id in val_patient_ids:\n",
    "            val_image_paths.extend(patient_image_paths[patient_id]['image_paths'])\n",
    "            val_labels.extend([patient_image_paths[patient_id]['label']] * len(patient_image_paths[patient_id]['image_paths']))\n",
    "\n",
    "        # Compute sample weights based on the training data\n",
    "        train_weights_dict = compute_sample_weights(train_patient_ids)\n",
    "        train_sample_weights = [train_weights_dict[patient_id] for patient_id in train_patient_ids]\n",
    "        train_sample_weights_expanded = []\n",
    "        for patient_id in train_patient_ids:\n",
    "            train_sample_weights_expanded.extend([train_weights_dict[patient_id]] * len(patient_image_paths[patient_id]['image_paths']))\n",
    "\n",
    "        train_ds = create_dataset(train_image_paths, train_labels, sample_weights=train_sample_weights_expanded, image_size=image_size, batch_size=batch_size, one_hot=True)\n",
    "        val_ds = create_dataset(val_image_paths, val_labels, image_size=image_size, batch_size=batch_size, one_hot=True)\n",
    "        \n",
    "        # Print number of images for each set and category\n",
    "        train_counts = count_images_per_category(train_image_paths, train_labels, categories)\n",
    "        val_counts = count_images_per_category(val_image_paths, val_labels, categories)\n",
    "        \n",
    "        print(f\"Fold {fold_no} - Training set counts: {train_counts}\")\n",
    "        print(f\"Fold {fold_no} - Validation set counts: {val_counts}\")\n",
    "        \n",
    "        # Apply data augmentation to the training dataset\n",
    "        data_augmentation = tf.keras.Sequential([\n",
    "            tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "            tf.keras.layers.RandomRotation(0.1),\n",
    "            tf.keras.layers.RandomZoom(0.1),\n",
    "            tf.keras.layers.RandomContrast(0.1)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        train_ds = train_ds.map(\n",
    "            lambda x, y, w: (data_augmentation(x, training=True), y, w),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "\n",
    "        print(f\"Training on fold {fold_no}...\")\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            print(\"tf.keras code in this scope will run on GPU\")\n",
    "            model = []\n",
    "            model = create_your_model() \n",
    "            metrics_callback = MetricsCallback(val_ds)\n",
    "            hist = model.fit(train_ds,\n",
    "                             validation_data=val_ds,\n",
    "                             epochs=epochs,\n",
    "                             verbose=1,\n",
    "                             callbacks=[metrics_callback, advanced_scheduler])\n",
    "            print(f\"Model_Average accuracy on fold {fold_no}: \", max(hist.history[\"val_accuracy\"]))\n",
    "            plot_training_history(hist)\n",
    "\n",
    "            metrics = metrics_callback.get_metrics()\n",
    "            all_accuracies.append(metrics['average_accuracy'])\n",
    "            all_sensitivities.append(metrics['average_sensitivity'])\n",
    "            all_specificities.append(metrics['average_specificity'])\n",
    "            all_f1_scores.append(metrics['average_f1'])\n",
    "            all_ious.append(metrics['average_iou'])\n",
    "\n",
    "            # Define the directory and file name\n",
    "            directory = 'C:/Users/39351/Documents/GitHub/Keras_Integrated_Classifier_STN_CNN/best_model'\n",
    "            file_name = 'L_ViT' + str(fold_no) + '.hdf5'\n",
    "\n",
    "            # Check if the directory exists, if not, create it\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "            p = os.path.join(directory, file_name)\n",
    "            print(p)\n",
    "\n",
    "            # Save the model\n",
    "            #model.save(p, overwrite=True)\n",
    "            #model.save('best_model/L_ViT'+str(fold_no)+'.hdf5', overwrite=True)\n",
    "           \n",
    "        \n",
    "        fold_no += 1\n",
    "\n",
    "    # Compute the average and standard deviation for each metric\n",
    "    avg_accuracy = np.mean(all_accuracies)\n",
    "    std_accuracy = np.std(all_accuracies)\n",
    "    \n",
    "    avg_sensitivity = np.mean(all_sensitivities)\n",
    "    std_sensitivity = np.std(all_sensitivities)\n",
    "    \n",
    "    avg_specificity = np.mean(all_specificities)\n",
    "    std_specificity = np.std(all_specificities)\n",
    "    \n",
    "    avg_f1_score = np.mean(all_f1_scores)\n",
    "    std_f1_score = np.std(all_f1_scores)\n",
    "    \n",
    "    avg_iou = np.mean(all_ious)\n",
    "    std_iou = np.std(all_ious)\n",
    "\n",
    "    print(\"\\nOverall Average Metrics across all folds:\")\n",
    "    print(f\"Average Accuracy: {avg_accuracy} ± {std_accuracy}\")\n",
    "    print(f\"Average Sensitivity: {avg_sensitivity} ± {std_sensitivity}\")\n",
    "    print(f\"Average Specificity: {avg_specificity} ± {std_specificity}\")\n",
    "    print(f\"Average F1 Score: {avg_f1_score} ± {std_f1_score}\")\n",
    "    print(f\"Average IoU: {avg_iou} ± {std_iou}\")\n",
    "\n",
    "# Assuming you have a function to create your model\n",
    "def create_your_model():\n",
    "    mdl = []\n",
    "    mdl = create_model(img_height=32, img_width=32, num_classes=3)\n",
    "    #model_name = 'MobileNetV3Large'\n",
    "    #mdl = create_base_model(model_name,img_height=32, img_width=32, num_classes=4)\n",
    "    mdl.summary()\n",
    "    #mdl.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    mdl.compile(optimizer= optimizer, loss = weighted_focal_loss(), metrics=['accuracy'])\n",
    "    return mdl\n",
    "\n",
    "# Parameters\n",
    "data_dir = 'D:/5-Histo-Cell-Dataset'  # Replace with your dataset directory\n",
    "k = 3  # Number of folds\n",
    "image_size = (img_width, img_height)\n",
    "\n",
    "# Run cross-validation\n",
    "cross_validate(data_dir, k, image_size, batch_size, epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFgpuKeras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
